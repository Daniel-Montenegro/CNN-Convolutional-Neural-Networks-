{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este codigo se pretende realizar una red neuronal que pueda clasificar digitos escritos a mano. Para ello se usa la arquitectura de $\\bf{LeNet-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using MXNet backend\n"
     ]
    }
   ],
   "source": [
    "#importar librerias \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Convolution2D as conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diseno de la red\n",
    "\n",
    "model = Sequential()\n",
    "#Layer 1\n",
    "model.add(conv2D(filters = 6, \n",
    "                 kernel_size=(5,5),\n",
    "                 data_format ='channels_first',\n",
    "                 activation ='relu', \n",
    "                 input_shape=(1,28,28)))\n",
    "\n",
    "#Layer 2\n",
    "\"\"\"\n",
    "model.add(AveragePooling2D(pool_size=(14,14),\n",
    "                           data_format='channels_first'))\n",
    "\"\"\"                    \n",
    "model.add(MaxPooling2D(pool_size=(2,2), \n",
    "                       data_format='channels_first'))\n",
    "\n",
    "\n",
    "#Layer 3\n",
    "model.add(conv2D(filters = 16,\n",
    "                kernel_size = (5,5),\n",
    "                data_format = 'channels_first',\n",
    "                activation = 'relu',\n",
    "                input_shape = (1,14,14)))\n",
    "\n",
    "#Layer 4\n",
    "model.add(MaxPooling2D(pool_size=(2,2), \n",
    "                       data_format='channels_first'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten(data_format = 'channels_first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Layer 5\n",
    "\"\"\"\n",
    "model.add(conv2D(filters = 120,\n",
    "                kernel_size = (1,1),\n",
    "                data_format = 'channels_first',\n",
    "                activation = 'relu'))\n",
    "\"\"\"\n",
    "model.add(Dense(units = 120,\n",
    "                activation = 'relu'))\n",
    "\n",
    "#Layer 6\n",
    "model.add(Dense(units = 84,\n",
    "               activation = 'relu'))\n",
    "\n",
    "#Layer 7\n",
    "model.add(Dense(units = 10,\n",
    "               activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los datos para el entrenamiento y el test\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# re-dimensionar mnist\n",
    "\n",
    "#dimension imagenes de entrada\n",
    "img_filas, img_columnas = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_filas, img_columnas)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_filas, img_columnas)\n",
    "    input_shape = (1, img_filas, img_columnas)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_filas, img_columnas, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_filas, img_columnas, 1)\n",
    "    input_shape = (img_filas, img_columnas, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#Convierte el y_train y y_test en numeros binarios para la comparacion\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilar red neuronal \n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer= 'adam',loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1000/60000 [..............................] - ETA: 1:29 - loss: 14.2904 - acc: 0.1000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.001). Is this intended?\n",
      "  force_init=force_init)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 39us/step - loss: 6.3996 - acc: 0.4026\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.8789 - acc: 0.7305\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5811 - acc: 0.8225\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4494 - acc: 0.8620\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3727 - acc: 0.8852\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3226 - acc: 0.9020\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.2814 - acc: 0.9143\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.2577 - acc: 0.9197\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.2296 - acc: 0.9282\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.2114 - acc: 0.9340\n",
      "time training 9.095125 [s]\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "\n",
    "import time \n",
    "time_star  = time.time()\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size = 1000,\n",
    "          epochs = 10,\n",
    "          shuffle= True)\n",
    "\n",
    "time_end = time.time()\n",
    "time = (time_end-time_star)\n",
    "\n",
    "print('time training %f [s]'%time)\n",
    "#print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08249817731846124, 0.9718]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resultados y comparación\n",
    "### Nota: los resultados en cada ejecución cambia debido al caracter  \"euristico\" del entrenamiento\n",
    "\n",
    "$\\star$ Dropout $\\bf{None}$ - Optimizer = $adam$ - loss = $categorical$_$crossentropy$\n",
    "\n",
    "    loss: 0.04,  acc: 0.988, time ejecution: 8.8681 [s]\n",
    "\n",
    "$\\star$ Dropout $\\bf{True}(0.25)$ - Optimizer = $adam$ - loss = $categorical$_$crossentropy$\n",
    "\n",
    "    loss: 0.07,  acc: 0.977, time ejecution: 9.1025 [s]\n",
    "\n",
    "$\\star$ Dropout $\\bf{True}(0.5)$ - Optimizer = $adam$ - loss = $categorical$_$crossentropy$\n",
    "\n",
    "    loss: 0.08,  acc: 0.971, time ejecution: 9.0951 [s]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
